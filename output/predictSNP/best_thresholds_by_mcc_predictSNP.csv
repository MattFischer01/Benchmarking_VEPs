"column","threshold","n","accuracy","sensitivity","specificity","precision","f1","mcc","auc"
"REVEL_rankscore",0.7,15446,0.903534895765894,0.94917001752758,0.826518183400035,0.902283642066059,0.92513315244699,0.791803453178099,0.960400395743442
"MetaRNN_rankscore",0.7,15798,0.873275098113685,0.868744955609362,0.880903839619436,0.924720790378007,0.895859342488556,0.736781422941318,0.94768917201924
"DEOGEN2_rankscore",0.7,15368,0.864653826132223,0.902167182662539,0.800634026065516,0.885355479035852,0.893682273563688,0.707784737517003,0.93275562333719
"MutScore_rankscore",0.8,15785,0.822869813113716,0.784513140670627,0.88793987017424,0.922339292056351,0.847861573620633,0.651245434345707,0.903313964751043
"AlphaMissense_rankscore",0.5,15843,0.784762986808054,0.82250907624042,0.721612957651426,0.831735672037528,0.82709664334246,0.542157541226087,0.839128466532403
"MutPred2_rankscore",0.6,15802,0.783445133527402,0.810593900481541,0.737058621871786,0.840441023507385,0.825247676437545,0.541458415343543,0.846739554576015
"CADD_raw_rankscore",0.5,15923,0.7623563398857,0.842791257268899,0.627500420238696,0.791376388627377,0.816275004855312,0.482771816936991,0.798767137472203
"SIFT_converted_rankscore",0.6,15225,0.727290640394089,0.715628917676557,0.747036971519547,0.827294685990338,0.767421017252969,0.448804317182695,0.788952585482644
"SIFT4G_converted_rankscore",0.5,15455,0.731219670009706,0.782338951504498,0.645746887966805,0.786895475819033,0.784610598361506,0.427267272291108,0.773136260780509
"PrimateAI_rankscore",0.4,15438,0.719458479077601,0.797282222898286,0.581854043392505,0.77123798312733,0.784043879331838,0.384549697779681,0.749291337505983
