"column","threshold","n","accuracy","sensitivity","specificity","precision","f1","mcc","auc"
"REVEL_rankscore",0.6,15446,0.887867409037939,0.975152077533766,0.740560292326431,0.863823180199105,0.916117783804727,0.76150705264308,0.960400395743442
"MetaRNN_rankscore",0.6,15798,0.874604380301304,0.902542372881356,0.827556914712878,0.898102600140548,0.900317013032758,0.731351882380704,0.94768917201924
"DEOGEN2_rankscore",0.6,15368,0.852290473711608,0.938080495356037,0.705882352941177,0.844795539033457,0.888997555012225,0.67835655251453,0.93275562333719
"MutScore_rankscore",0.6,15785,0.82768451061134,0.878864162722787,0.74086094977793,0.851927769643729,0.865186360031721,0.627207266544752,0.903313964751043
"MutPred2_rankscore",0.6,15802,0.783445133527402,0.810593900481541,0.737058621871786,0.840441023507385,0.825247676437545,0.541458415343543,0.846739554576015
"AlphaMissense_rankscore",0.6,15843,0.769551221359591,0.756353368293667,0.791631516787582,0.858614768174013,0.804246421103426,0.533149661815078,0.839128466532403
"CADD_raw_rankscore",0.6,15923,0.751428750863531,0.771505915379988,0.717767692049084,0.820887561339876,0.795431052305148,0.481014852107259,0.798767137472203
"SIFT_converted_rankscore",0.6,15225,0.727290640394089,0.715628917676557,0.747036971519547,0.827294685990338,0.767421017252969,0.448804317182695,0.788952585482644
"SIFT4G_converted_rankscore",0.6,15455,0.715173083144613,0.706441939820081,0.729771784232365,0.813817748659917,0.756337872246208,0.423776098340794,0.773136260780509
"PrimateAI_rankscore",0.6,15438,0.637453037958285,0.562316195112058,0.770306616460463,0.812335188983299,0.664589201174567,0.321719717968293,0.749291337505983
