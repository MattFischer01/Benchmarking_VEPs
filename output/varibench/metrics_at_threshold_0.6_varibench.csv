"column","threshold","n","accuracy","sensitivity","specificity","precision","f1","mcc","auc"
"DEOGEN2_rankscore",0.6,9782,0.782457575138009,0.936372269705603,0.666068222621185,0.679531357684356,0.787539936102236,0.607281208023639,0.906799287664039
"REVEL_rankscore",0.6,9983,0.786537113092257,0.932246798603027,0.676511954992968,0.685147159479808,0.789821481408423,0.611791981092968,0.891069162618359
"MetaRNN_rankscore",0.6,10137,0.763440860215054,0.710373636574611,0.802676733013041,0.726905723106151,0.718544600938967,0.514676784640658,0.869886841207841
"MutScore_rankscore",0.6,10141,0.697958781185287,0.717325227963526,0.683833560709413,0.623323852092645,0.66702902489401,0.396386143207398,0.776064471724612
"AlphaMissense_rankscore",0.6,10112,0.693829113924051,0.624824684431978,0.744429208090504,0.64193083573487,0.633262260127932,0.370670346771245,0.727278773830376
"SIFT_converted_rankscore",0.6,9841,0.663652067879281,0.637769447047798,0.683473891979185,0.606776638430673,0.621887137308659,0.319654988257072,0.705733507096994
"PrimateAI_rankscore",0.6,9813,0.632935901355345,0.419378517249817,0.78536500174642,0.582398912674142,0.487624466571835,0.22027471829304,0.676189554623201
"SIFT4G_converted_rankscore",0.6,9906,0.638400969109631,0.601025402004195,0.666963490650045,0.579680827152169,0.590160183066362,0.266970178571218,0.671229704201861
"MutPred2_rankscore",0.6,10128,0.641982622432859,0.572058482246461,0.693761814744801,0.580409700965387,0.576203833567087,0.266338435505524,0.671180459686821
"CADD_raw_rankscore",0.6,10207,0.635250318408935,0.559294499883964,0.690742624618515,0.569201700519603,0.564204611963011,0.250653309208388,0.659527744850357
